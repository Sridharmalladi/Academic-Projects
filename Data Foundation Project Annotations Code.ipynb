{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Miners Final Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/sridharmalladi/Desktop/DF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text_Sample</th>\n",
       "      <th>Tech</th>\n",
       "      <th>Political</th>\n",
       "      <th>Business</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Usually waze is my go to. But today it didnâ€™...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Adderall shortage is a real problem. I'm a...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This is my first ever comment/post on Reddit. ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This article is hardly an article and more of ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I can help with the cell phone part since I'm ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                        Text_Sample Tech Political  \\\n",
       "0   0  Usually waze is my go to. But today it didnâ€™...  Yes        No   \n",
       "1   1  The Adderall shortage is a real problem. I'm a...   No        No   \n",
       "2   2  This is my first ever comment/post on Reddit. ...  Yes       Yes   \n",
       "3   3  This article is hardly an article and more of ...  Yes       Yes   \n",
       "4   4  I can help with the cell phone part since I'm ...  Yes        No   \n",
       "\n",
       "  Business Entertainment Misc  \n",
       "0       No            No   No  \n",
       "1      Yes            No   No  \n",
       "2       No            No   No  \n",
       "3      Yes            No   No  \n",
       "4      Yes            No   No  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and display sample of data\n",
    "data = pd.read_excel('RedditMiners_GoldenDataset.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to be constructed:\n",
    "\n",
    "Sentiment - positive, neutral, negative\n",
    "\n",
    "Length of sample - numerical \n",
    "\n",
    "Presence of web address - binary\n",
    "\n",
    "Count of words in emotional lexicons - Anger, Joy, Sadness, Surprise, Anticipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update dataframe to have columns relating to variables\n",
    "\n",
    "data['Positive'] = None\n",
    "data['Neutral'] = None\n",
    "data['Negative'] = None\n",
    "data['Length'] = None\n",
    "data['Web Address'] = None\n",
    "data['Anger'] = None\n",
    "data['Joy'] = None\n",
    "data['Sadness'] = None\n",
    "data['Surprise'] = None\n",
    "data['Anticipation'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sentinement analysis, code taken from PS3 \n",
    "\n",
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Initalize the Lexicon classifer by loading lexicons. \n",
    "        \"\"\"\n",
    "        self.positive_words = set()\n",
    "        with open('positive-words.txt', encoding = 'utf-8') as iFile:\n",
    "            for row in iFile:\n",
    "                self.positive_words.add(row.strip())\n",
    "\n",
    "        self.negative_words = set()\n",
    "        with open('negative-words.txt', encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                self.negative_words.add(row.strip())\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns a sentiment prediction give an input string.\n",
    "            \n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is good good good\")\n",
    "            \n",
    "            Returns:\n",
    "            pred -- a string (\"postive, \"negative\", or \"neutral\")\n",
    "        \"\"\"\n",
    "        num_pos_words = 0\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.positive_words:\n",
    "                num_pos_words += 1\n",
    "            elif word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "        \n",
    "        pred = 'neutral'        \n",
    "        if num_pos_words > num_neg_words:\n",
    "            pred = 'positive'\n",
    "        elif num_pos_words < num_neg_words:\n",
    "            pred = 'negative'\n",
    "            \n",
    "        return pred\n",
    "    \n",
    "    def count_pos_words(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns the number of positive words in string\n",
    "            \n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is good good good\")\n",
    "            \n",
    "            Returns:\n",
    "            pred -- an integer (e.g., 3)\n",
    "        \"\"\"\n",
    "        num_pos_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.positive_words:\n",
    "                num_pos_words += 1\n",
    "        return num_pos_words\n",
    "\n",
    "    def count_neg_words(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns the number of negative words in string\n",
    "            \n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is good good good\")\n",
    "            \n",
    "            Returns:\n",
    "            pred -- an integer (e.g., 3)\n",
    "        \"\"\"\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "        return num_neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'positive-words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Changes values in dataframe based on sentiment prediction\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m lex_luthor \u001b[38;5;241m=\u001b[39m LexiconClassifier()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      6\u001b[0m     pred \u001b[38;5;241m=\u001b[39m lex_luthor\u001b[38;5;241m.\u001b[39mpredict(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText_Sample\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mLexiconClassifier.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Initalize the Lexicon classifer by loading lexicons. \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive-words.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m iFile:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m iFile:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive_words\u001b[38;5;241m.\u001b[39madd(row\u001b[38;5;241m.\u001b[39mstrip())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'positive-words.txt'"
     ]
    }
   ],
   "source": [
    "# Changes values in dataframe based on sentiment prediction\n",
    "\n",
    "lex_luthor = LexiconClassifier()\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    pred = lex_luthor.predict(data['Text_Sample'][i])\n",
    "    \n",
    "    if pred == 'positive':\n",
    "        data['Positive'][i] = 1\n",
    "        data['Neutral'][i] = 0\n",
    "        data['Negative'][i] = 0\n",
    "    \n",
    "    elif pred == 'neutral':\n",
    "        data['Positive'][i] = 0\n",
    "        data['Neutral'][i] = 1\n",
    "        data['Negative'][i] = 0\n",
    "        \n",
    "    elif pred == 'negative':\n",
    "        data['Positive'][i] = 0\n",
    "        data['Neutral'][i] = 0\n",
    "        data['Negative'][i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes value of length column for each sample\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    val = len(data['Text_Sample'][i].split())\n",
    "    \n",
    "    data['Length'][i] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length: 1429\n",
      "Min Length: 1\n"
     ]
    }
   ],
   "source": [
    "print('Max Length: ' + str(data['Length'].max()))\n",
    "print('Min Length: ' + str(data['Length'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Address Presence\n",
    "\n",
    "https://www.freecodecamp.org/news/how-to-write-a-regular-expression-for-a-url/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes web address column to 1 if text sample contains a web address \n",
    "# Regexpression taken from link above, helped capture some addresses I couldn't seem to catch properly\n",
    "\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    sam = data['Text_Sample'][i]\n",
    "    \n",
    "    if re.search(r'(https:\\/\\/www\\.|http:\\/\\/www\\.|https:\\/\\/|http:\\/\\/)?[a-zA-Z0-9]{2,}(\\.[a-zA-Z0-9]{2,})(\\.[a-zA-Z0-9]{2,})?', sam):\n",
    "        data['Web Address'][i] = 1\n",
    "    else:\n",
    "        data['Web Address'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    792\n",
       "1    208\n",
       "Name: Web Address, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Web Address'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a list of emotion associated words from lexicon\n",
    "# Taken from my submission of Problem set 2\n",
    "\n",
    "def emotion_list(emotion):\n",
    "    file = emotion + '-NRC-Emotion-Lexicon.txt'\n",
    "    text = open(file)\n",
    "    \n",
    "    emoList = list()\n",
    "    \n",
    "    for row in text: \n",
    "        info = row.split('\\t')\n",
    "        if info[1] == '1\\n':\n",
    "            emoList.append(info[0])\n",
    "        \n",
    "        elif info[1] == '0\\n':\n",
    "            break\n",
    "        \n",
    "    text.close()\n",
    "    \n",
    "    return emoList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lexicon words to list\n",
    "\n",
    "emotions = ['anger', 'joy', 'sadness', 'surprise', 'anticipation']\n",
    "\n",
    "# Creates a dictionary to use emotes as the keys, then the values as the generated list from the files\n",
    "emoteDict = dict()\n",
    "\n",
    "for emot in emotions:\n",
    "    \n",
    "    emoteDict[emot] = emotion_list(emot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates count of words belonging to each emotion in respective emotion column for 5 listed emotions\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    angcount = 0\n",
    "    joycount = 0\n",
    "    sadcount = 0\n",
    "    surpcount = 0\n",
    "    antcount = 0\n",
    "    \n",
    "    sam = data['Text_Sample'][i]\n",
    "    words = sam.split()\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in emoteDict['anger']:\n",
    "            angcount += 1\n",
    "        \n",
    "        if word in emoteDict['joy']:\n",
    "            joycount += 1\n",
    "            \n",
    "        if word in emoteDict['sadness']:\n",
    "            sadcount += 1\n",
    "            \n",
    "        if word in emoteDict['surprise']:\n",
    "            surpcount += 1\n",
    "        \n",
    "        if word in emoteDict['anticipation']:\n",
    "            antcount += 1\n",
    "        \n",
    "    data['Anger'][i] = angcount\n",
    "    data['Joy'][i] = joycount\n",
    "    data['Sadness'][i] = sadcount\n",
    "    data['Surprise'][i] = surpcount\n",
    "    data['Anticipation'][i] = antcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifies target label data to integers, yes = 1, no = 1\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    if data['Tech'][i] == 'Yes':\n",
    "        data['Tech'][i] = 1\n",
    "    else:\n",
    "        data['Tech'][i] = 0\n",
    "        \n",
    "    if data['Political'][i] == 'Yes':\n",
    "        data['Political'][i] = 1\n",
    "    else:\n",
    "        data['Political'][i] = 0\n",
    "        \n",
    "    if data['Business'][i] == 'Yes':\n",
    "        data['Business'][i] = 1\n",
    "    else:\n",
    "        data['Business'][i] = 0\n",
    "        \n",
    "    if data['Entertainment'][i] == 'Yes':\n",
    "        data['Entertainment'][i] = 1\n",
    "    else:\n",
    "        data['Entertainment'][i] = 0\n",
    "        \n",
    "    if data['Misc'][i] == 'Yes':\n",
    "        data['Misc'][i] = 1\n",
    "    else:\n",
    "        data['Misc'][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text_Sample</th>\n",
       "      <th>Tech</th>\n",
       "      <th>Political</th>\n",
       "      <th>Business</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Misc</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Length</th>\n",
       "      <th>Web Address</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Usually waze is my go to. But today it didnâ€™...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Adderall shortage is a real problem. I'm a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This is my first ever comment/post on Reddit. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This article is hardly an article and more of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I can help with the cell phone part since I'm ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                        Text_Sample Tech Political  \\\n",
       "0   0  Usually waze is my go to. But today it didnâ€™...    1         0   \n",
       "1   1  The Adderall shortage is a real problem. I'm a...    0         0   \n",
       "2   2  This is my first ever comment/post on Reddit. ...    1         1   \n",
       "3   3  This article is hardly an article and more of ...    1         1   \n",
       "4   4  I can help with the cell phone part since I'm ...    1         0   \n",
       "\n",
       "  Business Entertainment Misc Positive Neutral Negative Length Web Address  \\\n",
       "0        0             0    0        0       1        0     20           0   \n",
       "1        1             0    0        0       0        1     18           0   \n",
       "2        0             0    0        0       0        1     60           0   \n",
       "3        1             0    0        0       1        0     60           0   \n",
       "4        1             0    0        0       1        0     81           0   \n",
       "\n",
       "  Anger Joy Sadness Surprise Anticipation  \n",
       "0     0   0       0        0            0  \n",
       "1     1   1       1        1            1  \n",
       "2     5   0       3        1            1  \n",
       "3     1   1       0        0            0  \n",
       "4     1   1       1        1            3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for variables and target labels\n",
    "\n",
    "x_cols = ['Text_Sample','Positive','Neutral','Negative','Length', 'Web Address', 'Anger', 'Joy', 'Sadness', 'Surprise', 'Anticipation']\n",
    "y_cols = ['Tech','Political', 'Business', 'Entertainment', 'Misc']\n",
    "\n",
    "X = data[x_cols]\n",
    "Y = data[y_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Sample</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Length</th>\n",
       "      <th>Web Address</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Usually waze is my go to. But today it didnâ€™...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Adderall shortage is a real problem. I'm a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is my first ever comment/post on Reddit. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This article is hardly an article and more of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help with the cell phone part since I'm ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text_Sample Positive Neutral  \\\n",
       "0  Usually waze is my go to. But today it didnâ€™...        0       1   \n",
       "1  The Adderall shortage is a real problem. I'm a...        0       0   \n",
       "2  This is my first ever comment/post on Reddit. ...        0       0   \n",
       "3  This article is hardly an article and more of ...        0       1   \n",
       "4  I can help with the cell phone part since I'm ...        0       1   \n",
       "\n",
       "  Negative Length Web Address Anger Joy Sadness Surprise Anticipation  \n",
       "0        0     20           0     0   0       0        0            0  \n",
       "1        1     18           0     1   1       1        1            1  \n",
       "2        1     60           0     5   0       3        1            1  \n",
       "3        0     60           0     1   1       0        0            0  \n",
       "4        0     81           0     1   1       1        1            3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tech</th>\n",
       "      <th>Political</th>\n",
       "      <th>Business</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tech Political Business Entertainment Misc\n",
       "0    1         0        0             0    0\n",
       "1    0         0        1             0    0\n",
       "2    1         1        0             0    0\n",
       "3    1         1        1             0    0\n",
       "4    1         0        1             0    0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to break data out of dataframe object and into numpy array\n",
    "\n",
    "def df_arr(df):\n",
    "    tlist = []\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        tlist.append(df.iloc[i].to_list())\n",
    "\n",
    "    arr = np.array(tlist)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_text = x_test[['Text_Sample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = df_arr(x_train[['Anger', 'Joy', 'Sadness', 'Surprise', 'Anticipation']])\n",
    "x_test1 = df_arr(x_test[['Anger', 'Joy', 'Sadness', 'Surprise', 'Anticipation']])\n",
    "\n",
    "x_train2 = df_arr(x_train[['Positive','Neutral','Negative']])\n",
    "x_test2 = df_arr(x_test[['Positive','Neutral','Negative']])\n",
    "\n",
    "x_train3 = df_arr(x_train[['Length', 'Web Address']])\n",
    "x_test3 = df_arr(x_test[['Length', 'Web Address']])\n",
    "\n",
    "x_train = df_arr(x_train[['Positive','Neutral','Negative', 'Length', 'Web Address', 'Anger', 'Joy', 'Sadness', 'Surprise', 'Anticipation']])\n",
    "x_test = df_arr(x_test[['Positive','Neutral','Negative', 'Length', 'Web Address', 'Anger', 'Joy', 'Sadness', 'Surprise', 'Anticipation']])\n",
    "\n",
    "#x_test_text = x_test['Text_Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech\n",
    "y_tech_train = df_arr(y_train[['Tech']])\n",
    "y_tech_test = df_arr(y_test[['Tech']])\n",
    "\n",
    "# Political\n",
    "y_pol_train = df_arr(y_train[['Political']])\n",
    "y_pol_test = df_arr(y_test[['Political']])\n",
    "\n",
    "# Business\n",
    "y_bus_train = df_arr(y_train[['Business']])\n",
    "y_bus_test = df_arr(y_test[['Business']])\n",
    "\n",
    "# Entertainment\n",
    "y_ent_train = df_arr(y_train[['Entertainment']])\n",
    "y_ent_test = df_arr(y_test[['Entertainment']])\n",
    "\n",
    "# Misc\n",
    "y_misc_train = df_arr(y_train[['Misc']])\n",
    "y_misc_test = df_arr(y_test[['Misc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data(x_train, y_train, x_test, y_test, label):\n",
    "    \n",
    "    cols = ['Macro Prec', 'Micro Prec', 'Macro Recall', 'Micro Recall', 'Macro F1', 'Micro F1']\n",
    "    mod_data = pd.DataFrame(index = ['SVC', 'LinearSVC'], columns = cols)\n",
    "    \n",
    "    clf = SVC()\n",
    "    clf2 = LinearSVC()\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    clf2.fit(x_train, y_train)\n",
    "\n",
    "    preds = clf.predict(x_test)\n",
    "    preds2 = clf2.predict(x_test)\n",
    "    \n",
    "    fold = 5\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv = fold)\n",
    "    scores2 = cross_val_score(clf2, x_train, y_train, cv = fold)\n",
    "    \n",
    "    avgsc1 = sum(scores)/len(scores)\n",
    "    avgsc2 = sum(scores2)/len(scores2)\n",
    "    \n",
    "    prec11 = precision_score(y_test, preds, average = 'macro')\n",
    "    prec12 = precision_score(y_test, preds, average = 'micro')\n",
    "    mod_data['Macro Prec'][0] = prec11\n",
    "    mod_data['Micro Prec'][0] = prec12\n",
    "    \n",
    "    prec21 = precision_score(y_test, preds2, average = 'macro')\n",
    "    prec22 = precision_score(y_test, preds2, average = 'micro')\n",
    "    mod_data['Macro Prec'][1] = prec21\n",
    "    mod_data['Micro Prec'][1] = prec22\n",
    "    \n",
    "    recall11 = recall_score(y_test, preds, average = 'macro')\n",
    "    recall12 = recall_score(y_test, preds, average = 'micro')\n",
    "    mod_data['Macro Recall'][0] = recall11\n",
    "    mod_data['Micro Recall'][0] = recall12\n",
    "    \n",
    "    recall21 = recall_score(y_test, preds2, average = 'macro')\n",
    "    recall22 = recall_score(y_test, preds2, average = 'micro')\n",
    "    mod_data['Macro Recall'][1] = recall21\n",
    "    mod_data['Micro Recall'][1] = recall22\n",
    "    \n",
    "    \n",
    "    f1_11 = f1_score(y_test, preds, average = 'macro')\n",
    "    f1_12 = f1_score(y_test, preds, average = 'micro')\n",
    "    mod_data['Macro F1'][0] = f1_11\n",
    "    mod_data['Micro F1'][0] = f1_12\n",
    "    \n",
    "    f1_21 = f1_score(y_test, preds2, average = 'macro')\n",
    "    f1_22 = f1_score(y_test, preds2, average = 'micro')\n",
    "    mod_data['Macro F1'][1] = f1_21\n",
    "    mod_data['Micro F1'][1] = f1_22\n",
    "    \n",
    "#     print('Precision macro score for SVC under the {} label: {}'.format(label, round(prec11,3)))\n",
    "#     print('Precision micro score for SVC under the {} label: {}'.format(label, round(prec12,3)))\n",
    "#     print('Precision macro score for LinearSVC under the {} label: {}'.format(label, round(prec21,3)))\n",
    "#     print('Precision micro score for LinearSVC under the {} label: {}'.format(label, round(prec22,3)))\n",
    "#     print()\n",
    "#     print('Recall macro score for SVC under the {} label: {}'.format(label, round(recall11,3)))\n",
    "#     print('Recall micro score for SVC under the {} label: {}'.format(label, round(recall12,3)))\n",
    "#     print('Recall macro score for LinearSVC under the {} label: {}'.format(label, round(recall21,3)))\n",
    "#     print('Recall micro score for LinearSVC under the {} label: {}'.format(label, round(recall22,3)))\n",
    "#     print()\n",
    "#     print('F1 macro score for SVC under the {} label: {}'.format(label, round(f1_11,3)))\n",
    "#     print('F1 micro score for SVC under the {} label: {}'.format(label, round(f1_12,3)))\n",
    "#     print('F1 macro score for LinearSVC under the {} label: {}'.format(label, round(f1_21,3)))\n",
    "#     print('F1 micro score for LinearSVC under the {} label: {}'.format(label, round(f1_22,3)))\n",
    "#     print()\n",
    "#     print('Cross validation scores for SVC under the {} label: {}'.format(label, scores))\n",
    "#     print('Average {} fold cross validations score for SVC under the {} label: {}'.format(fold, label, round(avgsc1,3)))\n",
    "#     print('Cross validation scores for LinearSVC under the {} label: {}'.format(label, scores2))\n",
    "#     print('Average {} fold cross validation score for LinearSVC under the {} label: {}'.format(fold, label, round(avgsc2,3)))\n",
    "#     print()\n",
    "#     print('===========================================================================')\n",
    "#     print()\n",
    "\n",
    "    print(mod_data.head())\n",
    "    print()\n",
    "    print('===========================================================================')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set 0: All Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.882943   0.766667     0.507042     0.766667  0.447601  0.766667\n",
      "LinearSVC   0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.929766       0.86     0.511628         0.86  0.484957      0.86\n",
      "LinearSVC   0.875856   0.876667      0.57945     0.876667  0.603557  0.876667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.586202       0.58     0.556897         0.58    0.5275      0.58\n",
      "LinearSVC   0.594568   0.586667     0.593129     0.586667  0.586207  0.586667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.934783       0.87       0.5125         0.87  0.489507      0.87\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "LinearSVC   0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train, y_tech_train, x_test, y_tech_test, 'Tech')\n",
    "run_data(x_train, y_pol_train, x_test, y_pol_test, 'Political')\n",
    "run_data(x_train, y_bus_train, x_test, y_bus_test, 'Business')\n",
    "run_data(x_train, y_ent_train, x_test, y_ent_test, 'Entertainment')\n",
    "run_data(x_train, y_misc_train, x_test, y_misc_test, 'Miscellaneous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set 1: Anger, Joy, Sadness, Surprise, Anticipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.684746   0.766667      0.51676     0.766667   0.47268  0.766667\n",
      "LinearSVC   0.719388       0.77     0.523802         0.77  0.485982      0.77\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC          0.93266   0.866667     0.534884     0.866667  0.529116  0.866667\n",
      "LinearSVC    0.93266   0.866667     0.534884     0.866667  0.529116  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.561819   0.563333     0.539318     0.563333  0.504982  0.563333\n",
      "LinearSVC   0.559829   0.556667     0.527241     0.556667  0.467083  0.556667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.934783       0.87       0.5125         0.87  0.489507      0.87\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423077   0.843333     0.498031     0.843333  0.457505  0.843333\n",
      "LinearSVC   0.423077   0.843333     0.498031     0.843333  0.457505  0.843333\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train1, y_tech_train, x_test1, y_tech_test, 'Tech')\n",
    "run_data(x_train1, y_pol_train, x_test1, y_pol_test, 'Political')\n",
    "run_data(x_train1, y_bus_train, x_test1, y_bus_test, 'Business')\n",
    "run_data(x_train1, y_ent_train, x_test1, y_ent_test, 'Entertainment')\n",
    "run_data(x_train1, y_misc_train, x_test1, y_misc_test, 'Miscellaneous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set 2: Positive, Neutral, Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "LinearSVC   0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall Macro F1  Micro F1\n",
      "SVC         0.428333   0.856667          0.5     0.856667   0.4614  0.856667\n",
      "LinearSVC   0.428333   0.856667          0.5     0.856667   0.4614  0.856667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.592362   0.596667     0.587896     0.596667  0.586518  0.596667\n",
      "LinearSVC   0.592362   0.596667     0.587896     0.596667  0.586518  0.596667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "LinearSVC   0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train2, y_tech_train, x_test2, y_tech_test, 'Tech')\n",
    "run_data(x_train2, y_pol_train, x_test2, y_pol_test, 'Political')\n",
    "run_data(x_train2, y_bus_train, x_test2, y_bus_test, 'Business')\n",
    "run_data(x_train2, y_ent_train, x_test2, y_ent_test, 'Entertainment')\n",
    "run_data(x_train2, y_misc_train, x_test2, y_misc_test, 'Miscellaneous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set 3: Length, Web Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.882943   0.766667     0.507042     0.766667  0.447601  0.766667\n",
      "LinearSVC   0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.929766       0.86     0.511628         0.86  0.484957      0.86\n",
      "LinearSVC   0.560354   0.653333       0.6137     0.653333  0.541823  0.653333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1 Micro F1\n",
      "SVC         0.586202       0.58     0.556897         0.58    0.5275     0.58\n",
      "LinearSVC   0.613665       0.56     0.581857         0.56  0.536169     0.56\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.934783       0.87       0.5125         0.87  0.489507      0.87\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "LinearSVC   0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train3, y_tech_train, x_test3, y_tech_test, 'Tech')\n",
    "run_data(x_train3, y_pol_train, x_test3, y_pol_test, 'Political')\n",
    "run_data(x_train3, y_bus_train, x_test3, y_bus_test, 'Business')\n",
    "run_data(x_train3, y_ent_train, x_test3, y_ent_test, 'Entertainment')\n",
    "run_data(x_train3, y_misc_train, x_test3, y_misc_test, 'Miscellaneous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Label Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.882943   0.766667     0.507042     0.766667  0.447601  0.766667\n",
      "LinearSVC   0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.684746   0.766667      0.51676     0.766667   0.47268  0.766667\n",
      "LinearSVC   0.719388       0.77     0.523802         0.77  0.485982      0.77\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "LinearSVC   0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.882943   0.766667     0.507042     0.766667  0.447601  0.766667\n",
      "LinearSVC   0.381667   0.763333          0.5     0.763333  0.432892  0.763333\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train, y_tech_train, x_test, y_tech_test, 'Tech')\n",
    "run_data(x_train1, y_tech_train, x_test1, y_tech_test, 'Tech')\n",
    "run_data(x_train2, y_tech_train, x_test2, y_tech_test, 'Tech')\n",
    "run_data(x_train3, y_tech_train, x_test3, y_tech_test, 'Tech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Political Label Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.929766       0.86     0.511628         0.86  0.484957      0.86\n",
      "LinearSVC   0.428333   0.856667          0.5     0.856667    0.4614  0.856667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC          0.93266   0.866667     0.534884     0.866667  0.529116  0.866667\n",
      "LinearSVC    0.93266   0.866667     0.534884     0.866667  0.529116  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall Macro F1  Micro F1\n",
      "SVC         0.428333   0.856667          0.5     0.856667   0.4614  0.856667\n",
      "LinearSVC   0.428333   0.856667          0.5     0.856667   0.4614  0.856667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1 Micro F1\n",
      "SVC         0.929766       0.86     0.511628         0.86  0.484957     0.86\n",
      "LinearSVC   0.929766       0.86     0.511628         0.86  0.484957     0.86\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train, y_pol_train, x_test, y_pol_test, 'Tech')\n",
    "run_data(x_train1, y_pol_train, x_test1, y_pol_test, 'Tech')\n",
    "run_data(x_train2, y_pol_train, x_test2, y_pol_test, 'Tech')\n",
    "run_data(x_train3, y_pol_train, x_test3, y_pol_test, 'Tech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Label Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1 Micro F1\n",
      "SVC         0.586202       0.58     0.556897         0.58    0.5275     0.58\n",
      "LinearSVC   0.520134       0.54     0.500537         0.54  0.357143     0.54\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.561819   0.563333     0.539318     0.563333  0.504982  0.563333\n",
      "LinearSVC    0.55728   0.556667     0.528315     0.556667  0.473885  0.556667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.592362   0.596667     0.587896     0.596667  0.586518  0.596667\n",
      "LinearSVC   0.592362   0.596667     0.587896     0.596667  0.586518  0.596667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.586202       0.58     0.556897         0.58    0.5275      0.58\n",
      "LinearSVC   0.585714   0.576667     0.551664     0.576667  0.514965  0.576667\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train, y_bus_train, x_test, y_bus_test, 'Tech')\n",
    "run_data(x_train1, y_bus_train, x_test1, y_bus_test, 'Tech')\n",
    "run_data(x_train2, y_bus_train, x_test2, y_bus_test, 'Tech')\n",
    "run_data(x_train3, y_bus_train, x_test3, y_bus_test, 'Tech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entertainment Label Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.934783       0.87       0.5125         0.87  0.489507      0.87\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.934783       0.87       0.5125         0.87  0.489507      0.87\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "LinearSVC   0.433333   0.866667          0.5     0.866667  0.464286  0.866667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1 Micro F1\n",
      "SVC         0.934783       0.87       0.5125         0.87  0.489507     0.87\n",
      "LinearSVC   0.470517       0.83     0.489423         0.83   0.47225     0.83\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train, y_ent_train, x_test, y_ent_test, 'Tech')\n",
    "run_data(x_train1, y_ent_train, x_test1, y_ent_test, 'Tech')\n",
    "run_data(x_train2, y_ent_train, x_test2, y_ent_test, 'Tech')\n",
    "run_data(x_train3, y_ent_train, x_test3, y_ent_test, 'Tech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Label Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "LinearSVC   0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423077   0.843333     0.498031     0.843333  0.457505  0.843333\n",
      "LinearSVC   0.423077   0.843333     0.498031     0.843333  0.457505  0.843333\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "LinearSVC   0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "          Macro Prec Micro Prec Macro Recall Micro Recall  Macro F1  Micro F1\n",
      "SVC         0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "LinearSVC   0.423333   0.846667          0.5     0.846667  0.458484  0.846667\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_data(x_train, y_misc_train, x_test, y_misc_test, 'Tech')\n",
    "run_data(x_train1, y_misc_train, x_test1, y_misc_test, 'Tech')\n",
    "run_data(x_train2, y_misc_train, x_test2, y_misc_test, 'Tech')\n",
    "run_data(x_train3, y_misc_train, x_test3, y_misc_test, 'Tech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Test Data Tech Labeling\n",
    "\n",
    "Best model for the tech label appears to be the LinearSVC trained on the emotion based feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tech_mod = LinearSVC()\n",
    "best_tech_mod.fit(x_train1, y_tech_train)\n",
    "tech_preds = best_tech_mod.predict(x_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model for the political label appears to be the SVC trained on complete feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pol_mod = SVC()\n",
    "best_pol_mod.fit(x_train, y_pol_train)\n",
    "pol_preds = best_pol_mod.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model for the business label appears to be LinearSVC on the complete feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bus_mod = LinearSVC()\n",
    "best_bus_mod.fit(x_train, y_bus_train)\n",
    "bus_preds = best_bus_mod.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model for the entertainment label appears to be the SVC() on feature set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ent_mod = LinearSVC()\n",
    "best_ent_mod.fit(x_train3, y_ent_train)\n",
    "ent_preds = best_ent_mod.predict(x_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model for the miscellaneous label appears to be LinearSVC on feature set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_misc_mod = LinearSVC()\n",
    "best_misc_mod.fit(x_train3, y_misc_train)\n",
    "misc_preds = best_misc_mod.predict(x_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "\n",
    "Test text and ground truth labels alongside the best performing model for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>At the moment, it looks like NEISD is trying t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Google RV rental.\\n\\nYour best bet may be to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Ompomp is on the right track. Many classes wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Most computer repair involves replacing compon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Facebook page or website? Might drop by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Make sure ALL potential running water courses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Best picture I got from my phone using welding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>I think the coolest part of LEGOs is that you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Why arenâ€™t people more outraged about this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>I have 2G Google Fiber. If you have the networ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text_Sample\n",
       "530  At the moment, it looks like NEISD is trying t...\n",
       "926  Google RV rental.\\n\\nYour best bet may be to p...\n",
       "586  Ompomp is on the right track. Many classes wil...\n",
       "25   Most computer repair involves replacing compon...\n",
       "332            Facebook page or website? Might drop by\n",
       "..                                                 ...\n",
       "783  Make sure ALL potential running water courses ...\n",
       "592  Best picture I got from my phone using welding...\n",
       "664  I think the coolest part of LEGOs is that you ...\n",
       "709       Why arenâ€™t people more outraged about this\n",
       "221  I have 2G Google Fiber. If you have the networ...\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data = x_test_text.copy()\n",
    "out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Sample</th>\n",
       "      <th>Tech Truth</th>\n",
       "      <th>Political Truth</th>\n",
       "      <th>Business Truth</th>\n",
       "      <th>Entertainment Truth</th>\n",
       "      <th>Misc Truth</th>\n",
       "      <th>Tech Pred</th>\n",
       "      <th>Political Pred</th>\n",
       "      <th>Business Pred</th>\n",
       "      <th>Entertainment Pred</th>\n",
       "      <th>Misc Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>At the moment, it looks like NEISD is trying t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Google RV rental.\\n\\nYour best bet may be to p...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Ompomp is on the right track. Many classes wil...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Most computer repair involves replacing compon...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Facebook page or website? Might drop by</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Make sure ALL potential running water courses ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Best picture I got from my phone using welding...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>I think the coolest part of LEGOs is that you ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Why arenâ€™t people more outraged about this</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>I have 2G Google Fiber. If you have the networ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text_Sample Tech Truth  \\\n",
       "530  At the moment, it looks like NEISD is trying t...       None   \n",
       "926  Google RV rental.\\n\\nYour best bet may be to p...       None   \n",
       "586  Ompomp is on the right track. Many classes wil...       None   \n",
       "25   Most computer repair involves replacing compon...       None   \n",
       "332            Facebook page or website? Might drop by       None   \n",
       "..                                                 ...        ...   \n",
       "783  Make sure ALL potential running water courses ...       None   \n",
       "592  Best picture I got from my phone using welding...       None   \n",
       "664  I think the coolest part of LEGOs is that you ...       None   \n",
       "709       Why arenâ€™t people more outraged about this       None   \n",
       "221  I have 2G Google Fiber. If you have the networ...       None   \n",
       "\n",
       "    Political Truth Business Truth Entertainment Truth Misc Truth Tech Pred  \\\n",
       "530            None           None                None       None      None   \n",
       "926            None           None                None       None      None   \n",
       "586            None           None                None       None      None   \n",
       "25             None           None                None       None      None   \n",
       "332            None           None                None       None      None   \n",
       "..              ...            ...                 ...        ...       ...   \n",
       "783            None           None                None       None      None   \n",
       "592            None           None                None       None      None   \n",
       "664            None           None                None       None      None   \n",
       "709            None           None                None       None      None   \n",
       "221            None           None                None       None      None   \n",
       "\n",
       "    Political Pred Business Pred Entertainment Pred Misc Pred  \n",
       "530           None          None               None      None  \n",
       "926           None          None               None      None  \n",
       "586           None          None               None      None  \n",
       "25            None          None               None      None  \n",
       "332           None          None               None      None  \n",
       "..             ...           ...                ...       ...  \n",
       "783           None          None               None      None  \n",
       "592           None          None               None      None  \n",
       "664           None          None               None      None  \n",
       "709           None          None               None      None  \n",
       "221           None          None               None      None  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Tech Truth', 'Political Truth', 'Business Truth', 'Entertainment Truth', 'Misc Truth',\n",
    "       'Tech Pred', 'Political Pred', 'Business Pred', 'Entertainment Pred', 'Misc Pred']\n",
    "\n",
    "for col in cols:\n",
    "    out_data[col] = None\n",
    "    \n",
    "out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = out_data.reset_index()\n",
    "out_data = out_data.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Sample</th>\n",
       "      <th>Tech Truth</th>\n",
       "      <th>Political Truth</th>\n",
       "      <th>Business Truth</th>\n",
       "      <th>Entertainment Truth</th>\n",
       "      <th>Misc Truth</th>\n",
       "      <th>Tech Pred</th>\n",
       "      <th>Political Pred</th>\n",
       "      <th>Business Pred</th>\n",
       "      <th>Entertainment Pred</th>\n",
       "      <th>Misc Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At the moment, it looks like NEISD is trying t...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google RV rental.\\n\\nYour best bet may be to p...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ompomp is on the right track. Many classes wil...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most computer repair involves replacing compon...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook page or website? Might drop by</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Make sure ALL potential running water courses ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Best picture I got from my phone using welding...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>I think the coolest part of LEGOs is that you ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Why arenâ€™t people more outraged about this</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>I have 2G Google Fiber. If you have the networ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text_Sample Tech Truth  \\\n",
       "0    At the moment, it looks like NEISD is trying t...        Yes   \n",
       "1    Google RV rental.\\n\\nYour best bet may be to p...        Yes   \n",
       "2    Ompomp is on the right track. Many classes wil...        Yes   \n",
       "3    Most computer repair involves replacing compon...        Yes   \n",
       "4              Facebook page or website? Might drop by        Yes   \n",
       "..                                                 ...        ...   \n",
       "295  Make sure ALL potential running water courses ...        Yes   \n",
       "296  Best picture I got from my phone using welding...        Yes   \n",
       "297  I think the coolest part of LEGOs is that you ...        Yes   \n",
       "298       Why arenâ€™t people more outraged about this         No   \n",
       "299  I have 2G Google Fiber. If you have the networ...        Yes   \n",
       "\n",
       "    Political Truth Business Truth Entertainment Truth Misc Truth Tech Pred  \\\n",
       "0                No             No                  No         No       Yes   \n",
       "1                No            Yes                  No         No       Yes   \n",
       "2                No             No                  No        Yes       Yes   \n",
       "3                No            Yes                  No         No       Yes   \n",
       "4                No             No                  No         No       Yes   \n",
       "..              ...            ...                 ...        ...       ...   \n",
       "295              No             No                  No        Yes       Yes   \n",
       "296              No             No                  No        Yes       Yes   \n",
       "297              No             No                 Yes         No       Yes   \n",
       "298              No             No                  No        Yes       Yes   \n",
       "299              No            Yes                  No         No       Yes   \n",
       "\n",
       "    Political Pred Business Pred Entertainment Pred Misc Pred  \n",
       "0               No           Yes                 No        No  \n",
       "1               No            No                 No        No  \n",
       "2               No           Yes                 No        No  \n",
       "3               No            No                 No        No  \n",
       "4               No            No                 No        No  \n",
       "..             ...           ...                ...       ...  \n",
       "295             No            No                 No        No  \n",
       "296             No            No                 No        No  \n",
       "297             No           Yes                 No        No  \n",
       "298             No            No                 No        No  \n",
       "299             No            No                 No        No  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updates 'None' values with appropriate 'Yes' or 'No' based on various sources\n",
    "\n",
    "for i in range(out_data.shape[0]):\n",
    "    \n",
    "    # Ground truth labels for test samples\n",
    "    if y_tech_test[i] == 1:\n",
    "        out_data['Tech Truth'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Tech Truth'][i] = 'No'\n",
    "        \n",
    "    if y_pol_test[i] == 1:\n",
    "        out_data['Political Truth'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Political Truth'][i] = 'No'\n",
    "        \n",
    "    if y_bus_test[i] == 1:\n",
    "        out_data['Business Truth'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Business Truth'][i] = 'No'\n",
    "        \n",
    "    if y_ent_test[i] == 1:\n",
    "        out_data['Entertainment Truth'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Entertainment Truth'][i] = 'No'\n",
    "        \n",
    "    if y_misc_test[i] == 1:\n",
    "        out_data['Misc Truth'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Misc Truth'][i] = 'No'\n",
    "        \n",
    "    \n",
    "    # Prediction labels for test samples\n",
    "    if tech_preds[i] == 1:\n",
    "        out_data['Tech Pred'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Tech Pred'][i] = 'No'\n",
    "        \n",
    "    if pol_preds[i] == 1:\n",
    "        out_data['Political Pred'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Political Pred'][i] = 'No'\n",
    "        \n",
    "    if bus_preds[i] == 1:\n",
    "        out_data['Business Pred'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Business Pred'][i] = 'No'\n",
    "        \n",
    "    if ent_preds[i] == 1:\n",
    "        out_data['Entertainment Pred'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Entertainment Pred'][i] = 'No'\n",
    "        \n",
    "    if misc_preds[i] == 1:\n",
    "        out_data['Misc Pred'][i] = 'Yes'\n",
    "    else:\n",
    "        out_data['Misc Pred'][i] = 'No'\n",
    "        \n",
    "out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_data.to_csv('RedditMiners_PredictionsVsTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
